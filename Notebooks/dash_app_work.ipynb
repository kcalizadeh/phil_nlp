{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dash_app_work.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAhQpYfLeqGzGG+nVqQEyM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcalizadeh/phil_nlp/blob/master/dash_app_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXenaoRHXmAz"
      },
      "source": [
        "### Imports and Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2Al9oIXXvwS",
        "outputId": "54f30e6e-c287-4a87-d17e-662061f5ad94"
      },
      "source": [
        "# this cell mounts drive, sets the correct directory, then imports all functions\r\n",
        "# and relevant libraries via the functions.py file\r\n",
        "from google.colab import drive\r\n",
        "import sys\r\n",
        "\r\n",
        "# install relevent libraries not included with colab\r\n",
        "!pip install lime\r\n",
        "!pip install symspellpy\r\n",
        "!pip install jupyter-dash\r\n",
        "!pip install dash-bootstrap-components\r\n",
        "\r\n",
        "\r\n",
        "drive.mount('/gdrive',force_remount=True)\r\n",
        "\r\n",
        "drive_path = '/gdrive/MyDrive/Colab_Projects/Phil_NLP'\r\n",
        "\r\n",
        "sys.path.append(drive_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/86/91a13127d83d793ecb50eb75e716f76e6eda809b6803c5a4ff462339789e/lime-0.2.0.1.tar.gz (275kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 9.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 11.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 8.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 194kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 225kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 235kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 256kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->lime) (1.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-cp36-none-any.whl size=283846 sha256=0f6922bcc5eb79b188616ec9190cd5ebbd850daefa786a6de0be1045600c3499\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/4f/a5/0bc765457bd41378bf3ce8d17d7495369d6e7ca3b712c60c89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n",
            "Collecting symspellpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/af/e71fcca6a42b6a63f518b0c1627e1f67822815cb0cf71e6af05acbd75c78/symspellpy-6.7.0-py3-none-any.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.19.5)\n",
            "Installing collected packages: symspellpy\n",
            "Successfully installed symspellpy-6.7.0\n",
            "Collecting jupyter-dash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/b9/5f9499a0154124a262c85e3a99033b9b3a20dc3d2707b587f52b32b60d76/jupyter_dash-0.3.1-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (1.1.2)\n",
            "Collecting ansi2html\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/85/3a46be84afbb16b392a138cd396117f438c7b2e91d8dc327621d1ae1b5dc/ansi2html-1.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (5.5.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (4.10.1)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (1.3.3)\n",
            "Collecting dash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/17/55244363969638edd1151de0ea4aa10e6a7849b42d7d0994e3082514e19d/dash-1.18.1.tar.gz (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->jupyter-dash) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask->jupyter-dash) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->jupyter-dash) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->jupyter-dash) (1.1.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (51.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (1.0.18)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter-dash) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter-dash) (5.3.5)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from retrying->jupyter-dash) (1.15.0)\n",
            "Collecting flask-compress\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/7a/9c4641f975fb9daaf945dc39da6a52fd5693ab3bbc2d53780eab3b5106f4/Flask_Compress-1.8.0-py3-none-any.whl\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (4.4.1)\n",
            "Collecting dash_renderer==1.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/fe/59a322edb128ad15205002c7b81e3f5e580f6791c4a100183289e05dbfcb/dash_renderer-1.8.3.tar.gz (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 7.1MB/s \n",
            "\u001b[?25hCollecting dash-core-components==1.14.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/ab/5ffeeed41117383d02485f5b9204dcfaa074bfbb3ff2559afac7b904ad5c/dash_core_components-1.14.1.tar.gz (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 13.9MB/s \n",
            "\u001b[?25hCollecting dash-html-components==1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/ba/bb9427c62feb25bfbaf243894eeeb4e7c67a92b426ed0575a167100e436e/dash_html_components-1.1.1.tar.gz (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 38.5MB/s \n",
            "\u001b[?25hCollecting dash-table==4.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/4b/de20584b7dc82dc6e572e8b596d21b1c6e39f13d19e8c9e6f1d67bed67fd/dash_table-4.11.1.tar.gz (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 46.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->jupyter-dash) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->jupyter-dash) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->jupyter-dash) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->jupyter-dash) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->jupyter-dash) (1.1.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->jupyter-dash) (0.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyter-dash) (0.2.5)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (4.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (20.0.0)\n",
            "Collecting brotli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/d3/7c98f05b7b9103e2f3a112ba42f269c798155b3e5404fb80bb8f823aaebe/Brotli-1.0.9-cp36-cp36m-manylinux1_x86_64.whl (357kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 39.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: dash, dash-renderer, dash-core-components, dash-html-components, dash-table\n",
            "  Building wheel for dash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash: filename=dash-1.18.1-cp36-none-any.whl size=83681 sha256=ebfa11c5ec424cfa40f9ce308c5011cf34733f233e65575e710b55429c30aa8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/56/fb/79b2169ce9fcb79753ec57a16abb8f0b7750b4c63d7eb3cea9\n",
            "  Building wheel for dash-renderer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-renderer: filename=dash_renderer-1.8.3-cp36-none-any.whl size=1013945 sha256=1c410b94253d8238e41a27dcb19fd72efcba08f8d51a6afda9ebac0136fbc86b\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/2b/5f/0928a6d1b7ebf280f21a2e925f36d662e6ba83e00b82c6b6bf\n",
            "  Building wheel for dash-core-components (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-core-components: filename=dash_core_components-1.14.1-cp36-none-any.whl size=3525927 sha256=724796c7e5ea6c3b39af8babb783c1f55d46979f6c70ac7991deb9674e62ca35\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/20/48/9022e1f2cb2fed4d9925370d0e17cbb3ab1164f3742d9b5e5a\n",
            "  Building wheel for dash-html-components (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-html-components: filename=dash_html_components-1.1.1-cp36-none-any.whl size=427894 sha256=3a17d83b2cc97a7648681fd8bf0e28d96a4b1e4f0224bdd7396de05b91053a89\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/01/46/78e4de185a8a4a2da8ba31da16c52170f036d4cebeeb6e07a2\n",
            "  Building wheel for dash-table (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-table: filename=dash_table-4.11.1-cp36-none-any.whl size=1839869 sha256=4b6d5e970d2e1eeb28804342f101e67cbdad039f36a71c00ece7f6e7444f944d\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/a0/0e/1105943524ee7060c5c45a22e45c77777a3d8801f2fe49e445\n",
            "Successfully built dash dash-renderer dash-core-components dash-html-components dash-table\n",
            "Installing collected packages: ansi2html, brotli, flask-compress, dash-renderer, dash-core-components, dash-html-components, dash-table, dash, jupyter-dash\n",
            "Successfully installed ansi2html-1.6.0 brotli-1.0.9 dash-1.18.1 dash-core-components-1.14.1 dash-html-components-1.1.1 dash-renderer-1.8.3 dash-table-4.11.1 flask-compress-1.8.0 jupyter-dash-0.3.1\n",
            "Collecting dash-bootstrap-components\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/26/17f8b18a79bae9e278b7674ad0aef8007e87b4d2280525a95103fd2a8fe5/dash_bootstrap_components-0.11.1-py2.py3-none-any.whl (187kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dash>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from dash-bootstrap-components) (1.18.1)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (1.1.2)\n",
            "Requirement already satisfied: dash-html-components==1.1.1 in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (1.1.1)\n",
            "Requirement already satisfied: dash-table==4.11.1 in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (4.11.1)\n",
            "Requirement already satisfied: flask-compress in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (1.8.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (4.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (0.16.0)\n",
            "Requirement already satisfied: dash-core-components==1.14.1 in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (1.14.1)\n",
            "Requirement already satisfied: dash-renderer==1.8.3 in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (1.8.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.4->dash>=1.9.0->dash-bootstrap-components) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.4->dash>=1.9.0->dash-bootstrap-components) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.4->dash>=1.9.0->dash-bootstrap-components) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.4->dash>=1.9.0->dash-bootstrap-components) (2.11.2)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.6/dist-packages (from flask-compress->dash>=1.9.0->dash-bootstrap-components) (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly->dash>=1.9.0->dash-bootstrap-components) (1.15.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->dash>=1.9.0->dash-bootstrap-components) (1.3.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.4->dash>=1.9.0->dash-bootstrap-components) (1.1.1)\n",
            "Installing collected packages: dash-bootstrap-components\n",
            "Successfully installed dash-bootstrap-components-0.11.1\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcK2Wb4ZTfY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7be72c-56b3-4d6d-9ab0-64e8bf9884bf"
      },
      "source": [
        "%load_ext autoreload\r\n",
        "%autoreload 2\r\n",
        "from functions import *\r\n",
        "\r\n",
        "np.random.seed(17)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning:\n",
            "\n",
            "The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning:\n",
            "\n",
            "The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv08eNYlWOzj"
      },
      "source": [
        "### Text Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmHP47PsWSoI"
      },
      "source": [
        "In order to set up the text classifier via Lime, we need to build a pipeline that can tokenize and pad text for use with our neural network models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv6-A8_kGUUb"
      },
      "source": [
        "class Padder(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self, maxlen=500):\r\n",
        "        self.maxlen = maxlen\r\n",
        "        self.max_index = None\r\n",
        "        \r\n",
        "    def fit(self, X, y=None):\r\n",
        "        self.max_index = pad_sequences(X, maxlen=self.maxlen).max()\r\n",
        "        return self\r\n",
        "    \r\n",
        "    def transform(self, X, y=None):\r\n",
        "        X = pad_sequences(X, maxlen=self.maxlen)\r\n",
        "        # X[X > self.max_index] = 0\r\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKAdBCV-N4wm"
      },
      "source": [
        "class TextsToSequences(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self,  tokenizer):\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        \r\n",
        "    def fit(self, texts, y=None):\r\n",
        "        return self\r\n",
        "    \r\n",
        "    def transform(self, texts, y=None):\r\n",
        "        return np.array(self.tokenizer.texts_to_sequences(texts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6fdSOJ2WiCs"
      },
      "source": [
        "The following cell runs the app in the notebook. At this point it is unformatted, but the callbacks work and it will display a text analysis breakdown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gtorzn5X0IF"
      },
      "source": [
        "import plotly.express as px\r\n",
        "from jupyter_dash import JupyterDash\r\n",
        "import dash_core_components as dcc\r\n",
        "import dash_html_components as html\r\n",
        "import dash_bootstrap_components as dbc\r\n",
        "from dash.dependencies import Input, Output, State\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "\r\n",
        "# Load Data\r\n",
        "df = pd.read_csv('/gdrive/MyDrive/Colab_Projects/Phil_NLP/phil_nlp.csv')\r\n",
        "\r\n",
        "model_path = '/gdrive/MyDrive/Colab_Projects/Phil_NLP/checkpoints/NN_weights_epoch:07_0.7678.hdf5'\r\n",
        "model = load_model(model_path)\r\n",
        "\r\n",
        "with open('/gdrive/MyDrive/Colab_Projects/Phil_NLP/baseline_tokenizer.pkl', 'rb') as f:\r\n",
        "    tokenizer = pickle.load(f)\r\n",
        "\r\n",
        "# set up classification explanation pipeline\r\n",
        "padder = Padder(450)\r\n",
        "sequencer = TextsToSequences(tokenizer)\r\n",
        "pipeline = make_pipeline(sequencer, padder, model)\r\n",
        "\r\n",
        "# set up labels\r\n",
        "school_label_dict = {'analytic': 0,\r\n",
        " 'aristotle': 1,\r\n",
        " 'capitalism': 2,\r\n",
        " 'communism': 3,\r\n",
        " 'continental': 4,\r\n",
        " 'empiricism': 5,\r\n",
        " 'german_idealism': 6,\r\n",
        " 'phenomenology': 7,\r\n",
        " 'plato': 8,\r\n",
        " 'rationalism': 9}\r\n",
        "flipped_dict = {value:key for key, value in school_label_dict.items()}\r\n",
        "\r\n",
        "# search bar object\r\n",
        "search_bar = html.Div(id=\"search-bar-container\", children=\r\n",
        "    [\r\n",
        "        dbc.Input(id=\"search-bar\", placeholder=\"enter text to classify\", type=\"text\"),\r\n",
        "        dbc.Button(\"SUBMIT\", id=\"search-bar-submit-button\", color=\"primary\", className=\"mr-1\", n_clicks=0)\r\n",
        "    ])\r\n",
        "\r\n",
        "\r\n",
        "# the app itself\r\n",
        "app = JupyterDash(__name__)\r\n",
        "app.layout = html.Div([\r\n",
        "    html.H1(\"Text Classification\"),\r\n",
        "    search_bar,\r\n",
        "    html.Div(id=\"search-bar-output\", children=[])  \r\n",
        "])\r\n",
        "\r\n",
        "\r\n",
        "# callback for search bar\r\n",
        "@app.callback(Output(component_id=\"search-bar-output\", component_property=\"children\"),\r\n",
        "              [Input(component_id=\"search-bar-submit-button\", component_property=\"n_clicks\")],\r\n",
        "              [State(component_id=\"search-bar\", component_property=\"value\")])\r\n",
        "def generate_explainer_html(n_clicks, text):\r\n",
        "    empty_obj = html.Iframe(\r\n",
        "        srcDoc='''<div>Enter input text to see LIME explanations.</div>''',\r\n",
        "        width='100%',\r\n",
        "        height='100px',\r\n",
        "        style={'border': '2px #d3d3d3 solid'},\r\n",
        "        hidden=True,\r\n",
        "    )\r\n",
        "    if n_clicks < 1 or text == '':\r\n",
        "      return empty_obj\r\n",
        "    else:\r\n",
        "      explainer = lime_text.LimeTextExplainer(class_names=list(school_label_dict.keys()))\r\n",
        "      exp = explainer.explain_instance(text, \r\n",
        "                                       pipeline.predict, \r\n",
        "                                       num_features=10, \r\n",
        "                                       labels=[0,1,2,3,4,5,6,7,8,9],\r\n",
        "                                       top_labels=5)\r\n",
        "      obj = html.Iframe(\r\n",
        "          srcDoc=exp.as_html(),\r\n",
        "          width='100%',\r\n",
        "          height='800px',\r\n",
        "          style={'border': '2px #d3d3d3 solid'},\r\n",
        "      )\r\n",
        "      return obj\r\n",
        "\r\n",
        "\r\n",
        "# Run app and display result inline in the notebook\r\n",
        "app.run_server(mode='inline')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ritqCmr3NSo4"
      },
      "source": [
        "### W2V Explorer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkbtexxvNSO0"
      },
      "source": [
        "This app is designed to enable exploration of the texts via w2v models. Users can submit text to see how different philosophers use key terms. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "CIe4sQN6NRs0",
        "outputId": "f794df6d-8daf-467f-dd17-5a5b68b53638"
      },
      "source": [
        "import plotly.express as px\r\n",
        "from jupyter_dash import JupyterDash\r\n",
        "import dash_core_components as dcc\r\n",
        "import dash_html_components as html\r\n",
        "import dash_bootstrap_components as dbc\r\n",
        "from dash.dependencies import Input, Output, State\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "\r\n",
        "custom_vectors = KeyedVectors.load('/gdrive/MyDrive/Colab_Projects/Phil_NLP/w2v_models/test_w2v.wordvectors')\r\n",
        "\r\n",
        "# search bar object\r\n",
        "search_bar = html.Div(id=\"search-bar-container\", children=\r\n",
        "    [\r\n",
        "        dbc.Input(id=\"search-bar\", placeholder=\"enter text to classify\", type=\"text\"),\r\n",
        "        dbc.Button(\"SUBMIT\", id=\"search-bar-submit-button\", color=\"primary\", className=\"mr-1\", n_clicks=0)\r\n",
        "    ])\r\n",
        "\r\n",
        "\r\n",
        "# the app itself\r\n",
        "app = JupyterDash(__name__)\r\n",
        "app.layout = html.Div([\r\n",
        "    html.H1(\"Word Similarity Search\"),\r\n",
        "    search_bar,\r\n",
        "    html.Div(id=\"search-bar-output\", children=[])  \r\n",
        "])\r\n",
        "\r\n",
        "\r\n",
        "# callback for search bar\r\n",
        "@app.callback(Output(component_id=\"search-bar-output\", component_property=\"children\"),\r\n",
        "              [Input(component_id=\"search-bar-submit-button\", component_property=\"n_clicks\")],\r\n",
        "              [State(component_id=\"search-bar\", component_property=\"value\")])\r\n",
        "def generate_explainer_html(n_clicks, text):\r\n",
        "    empty_obj = html.Iframe(\r\n",
        "        srcDoc='''<div>Enter input text to see LIME explanations.</div>''',\r\n",
        "        width='100%',\r\n",
        "        height='100px',\r\n",
        "        style={'border': '2px #d3d3d3 solid'},\r\n",
        "        hidden=True,\r\n",
        "    )\r\n",
        "    if n_clicks < 1 or text == '':\r\n",
        "      return empty_obj\r\n",
        "    else:\r\n",
        "      try:\r\n",
        "        similar_words = custom_vectors.most_similar(text)\r\n",
        "        formatted = [f'{x[0].title()}, {round(x[1], 3)}\\t\\n\\n' for x in similar_words]\r\n",
        "        joined = '\\n- '.join(formatted)\r\n",
        "        return joined\r\n",
        "      except:\r\n",
        "        return 'Sorry, that word or phrase is not in the vocabulary'\r\n",
        "\r\n",
        "\r\n",
        "# Run app and display result inline in the notebook\r\n",
        "app.run_server(mode='inline')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = url + path;\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZCdXL_UeZUe"
      },
      "source": [
        "### Basic Info Comparison Display"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztMqxC23eb9g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFpQsp4secWf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA6reQ4becgF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN8I9i5-ecpP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOmL9cGlecw1"
      },
      "source": [
        "explainer = LimeTextExplainer()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "N7CjdrVOfnkf",
        "outputId": "fb85d674-dca5-4e71-806f-3b5edb6ff067"
      },
      "source": [
        "explainer.explain_instance()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d58c598b3d9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05q4fO6kay8C"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BIo730TX-qD"
      },
      "source": [
        "model_path = '/gdrive/MyDrive/Colab_Projects/Phil_NLP/checkpoints/NN_weights_epoch:07_0.7678.hdf5'\r\n",
        "model = load_model(model_path)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09l49K48bJsM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdivJ0n7PhfZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHjCt6bza31C",
        "outputId": "33577141-ef9f-43aa-81bb-730fcc832404"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10844288  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                35800     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                260       \n",
            "=================================================================\n",
            "Total params: 10,881,623\n",
            "Trainable params: 10,881,623\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJfu3Ae0a_q-"
      },
      "source": [
        "with open('/gdrive/MyDrive/Colab_Projects/Phil_NLP/baseline_tokenizer.pkl', 'rb') as f:\r\n",
        "    tokenizer = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlSrRWcEgBXq"
      },
      "source": [
        "to_classify = 'Knowledge of the Idea of the absolute ethical order depends entirely on the establishment of perfect adequacy between intuition and concept, because the Idea itself is nothing other than the identity of the two. But if this identity is to be actually known, it must be thought as a made adequacy.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdLwCxJ60ht8"
      },
      "source": [
        "pipeline = make_pipeline(sequencer, padder, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cm36OB4zP89",
        "outputId": "6f0ef697-d99d-4e21-ca57-d79f03b3702e"
      },
      "source": [
        "pd.Series(to_classify)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Knowledge of the Idea of the absolute ethical ...\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDP4U8aDgIH_"
      },
      "source": [
        "tokenized = tokenizer.texts_to_sequences(pd.Series(to_classify))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjwcZwrhgrVa"
      },
      "source": [
        "padded = sequence.pad_sequences(tokenized, maxlen=450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g2hXNQV5yR8"
      },
      "source": [
        "flipped_dict[pipeline.predict(pd.Series(to_classify)).argmax()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyZClxsmgc00",
        "outputId": "7cc5ffba-41ae-430b-ba29-b1b230f6b125"
      },
      "source": [
        "prediction_num = model.predict(padded, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpR4AOgpvrXY",
        "outputId": "6249c94e-5b2f-474b-fcfd-819f8b2565b0"
      },
      "source": [
        "prediction_num.argmax()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHuX7TCgzYin"
      },
      "source": [
        "flipped_dict[prediction_num.argmax()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv9-APXr29aC",
        "outputId": "3dd37204-65f1-44c1-c972-de9b8f7fb7c1"
      },
      "source": [
        "list(school_label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['analytic',\n",
              " 'aristotle',\n",
              " 'capitalism',\n",
              " 'communism',\n",
              " 'continental',\n",
              " 'empiricism',\n",
              " 'german_idealism',\n",
              " 'phenomenology',\n",
              " 'plato',\n",
              " 'rationalism']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuF8tsPb7CjO"
      },
      "source": [
        "to_classify = \"\"\"Hi Michelle and Kourosh-\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "Happy New Year to you both!\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "Was wondering if we could schedule a short touch base in the next few weeks? No concerns—rather—just want to get some feedback on Cole’s progress.\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "Could you suggest a few times that could work for you both?\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "thanks\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJk199u806kH"
      },
      "source": [
        "explainer = lime_text.LimeTextExplainer(class_names=list(school_label_dict.keys()))\r\n",
        "exp = explainer.explain_instance(to_classify, pipeline.predict, num_features=10, labels=[0,1,2,3,4,5,6,7,8,9])\r\n",
        "\r\n",
        "exp.show_in_notebook(text=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fN7cFP2hCNz"
      },
      "source": [
        "for i in prediction_num.argmax(axis=1):\r\n",
        "  print(flipped_dict[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pL78gvQgkpw"
      },
      "source": [
        "school_label_dict = {'analytic': 0,\r\n",
        " 'aristotle': 1,\r\n",
        " 'capitalism': 2,\r\n",
        " 'communism': 3,\r\n",
        " 'continental': 4,\r\n",
        " 'empiricism': 5,\r\n",
        " 'german_idealism': 6,\r\n",
        " 'phenomenology': 7,\r\n",
        " 'plato': 8,\r\n",
        " 'rationalism': 9}\r\n",
        "flipped_dict = {value:key for key, value in school_label_dict.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MaWbI7BhBdc"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.pipeline import TransformerMixin\r\n",
        "from sklearn.base import BaseEstimator\r\n",
        "\r\n",
        "class TextsToSequences(BaseEstimator, TransformerMixin):\r\n",
        "    \"\"\" Sklearn transformer to convert texts to indices list \r\n",
        "    (e.g. [[\"the cute cat\"], [\"the dog\"]] -> [[1, 2, 3], [1, 4]])\"\"\"\r\n",
        "    def __init__(self,  tokenizer, **kwargs):\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        \r\n",
        "    def fit(self, texts, y=None):\r\n",
        "        return self\r\n",
        "    \r\n",
        "    def transform(self, texts, y=None):\r\n",
        "        return np.array(self.tokenizer.texts_to_sequences(texts))\r\n",
        "        \r\n",
        "sequencer = TextsToSequences(tokenizer, num_words=450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiUHD02_4BAj"
      },
      "source": [
        "class Padder(BaseEstimator, TransformerMixin):\r\n",
        "    \"\"\" Pad and crop uneven lists to the same length. \r\n",
        "    Only the end of lists longer than the maxlen attribute are\r\n",
        "    kept, and lists shorter than maxlen are left-padded with zeros\r\n",
        "    \r\n",
        "    Attributes\r\n",
        "    ----------\r\n",
        "    maxlen: int\r\n",
        "        sizes of sequences after padding\r\n",
        "    max_index: int\r\n",
        "        maximum index known by the Padder, if a higher index is met during \r\n",
        "        transform it is transformed to a 0\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, maxlen=500):\r\n",
        "        self.maxlen = maxlen\r\n",
        "        self.max_index = None\r\n",
        "        \r\n",
        "    def fit(self, X, y=None):\r\n",
        "        self.max_index = pad_sequences(X, maxlen=self.maxlen).max()\r\n",
        "        return self\r\n",
        "    \r\n",
        "    def transform(self, X, y=None):\r\n",
        "        X = pad_sequences(X, maxlen=self.maxlen)\r\n",
        "        # X[X > self.max_index] = 0\r\n",
        "        return X\r\n",
        "\r\n",
        "padder = Padder(450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0amhwL1JbU4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}