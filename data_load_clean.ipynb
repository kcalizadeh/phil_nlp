{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_load_clean.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcalizadeh/phil_nlp/blob/master/data_load_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpcX3zNaezhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d57a50-d104-4048-cf71-0bf475de4592"
      },
      "source": [
        "# this cell mounts drive, sets the correct directory, then imports all functions\r\n",
        "# and relevant libraries via the functions.py file\r\n",
        "from google.colab import drive\r\n",
        "import sys\r\n",
        "\r\n",
        "# install relevent libraries not included with colab\r\n",
        "!pip install lime\r\n",
        "!pip install symspellpy\r\n",
        "\r\n",
        "drive.mount('/gdrive',force_remount=True)\r\n",
        "\r\n",
        "drive_path = '/gdrive/MyDrive/Colab_Projects/Phil_NLP'\r\n",
        "\r\n",
        "sys.path.append(drive_path)\r\n",
        "\r\n",
        "from functions import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/86/91a13127d83d793ecb50eb75e716f76e6eda809b6803c5a4ff462339789e/lime-0.2.0.1.tar.gz (275kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 14.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 19.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 10.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 194kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 225kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 235kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 256kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.19.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->lime) (1.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-cp36-none-any.whl size=283846 sha256=8868bbb7e7d563e0b31b2d95ff4f641417f76c95011b156125384edf03ea2b04\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/4f/a5/0bc765457bd41378bf3ce8d17d7495369d6e7ca3b712c60c89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n",
            "Collecting symspellpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/af/e71fcca6a42b6a63f518b0c1627e1f67822815cb0cf71e6af05acbd75c78/symspellpy-6.7.0-py3-none-any.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.19.4)\n",
            "Installing collected packages: symspellpy\n",
            "Successfully installed symspellpy-6.7.0\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9XjJfDf5zo0"
      },
      "source": [
        "With the functions loaded, we bring in the various texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKNj8xVynvwf"
      },
      "source": [
        "# load the texts\r\n",
        "\r\n",
        "## plato\r\n",
        "plato_complete = get_text(drive_path + '/phil_txts/plato_complete_works.txt')\r\n",
        "\r\n",
        "# aristotle\r\n",
        "aristotle_vol1 = get_text(drive_path + '/phil_txts/aristotle_complete_works_v1.txt')\r\n",
        "aristotle_vol2 = get_text(drive_path + '/phil_txts/aristotle_complete_works_v2.txt')\r\n",
        "\r\n",
        "## rationalists\r\n",
        "spinoza_ethics = get_guten('http://www.gutenberg.org/cache/epub/3800/pg3800.txt')\r\n",
        "spinoza_improve_understanding = get_guten('http://www.gutenberg.org/cache/epub/1016/pg1016.txt')\r\n",
        "leibniz_theodicy = get_guten('http://www.gutenberg.org/cache/epub/17147/pg17147.txt')\r\n",
        "descartes_discourse_method = get_guten('http://www.gutenberg.org/cache/epub/59/pg59.txt')\r\n",
        "descartes_meditations = get_text(drive_path + '/phil_txts/descartes_meditations.txt')\r\n",
        "malebranche_search_truth = get_text(drive_path + '/phil_txts/malebranche_search_truth.txt')\r\n",
        "\r\n",
        "## empiricists\r\n",
        "locke_understanding_1 = get_guten('http://www.gutenberg.org/cache/epub/10615/pg10615.txt')\r\n",
        "locke_understanding_2 = get_guten('http://www.gutenberg.org/cache/epub/10616/pg10616.txt')\r\n",
        "locke_treatise_gov = get_guten('http://www.gutenberg.org/cache/epub/7370/pg7370.txt')\r\n",
        "hume_treatise = get_guten('http://www.gutenberg.org/cache/epub/4705/pg4705.txt')\r\n",
        "hume_natural_religion = get_guten('http://www.gutenberg.org/cache/epub/4583/pg4583.txt')\r\n",
        "berkeley_treatise = get_guten('http://www.gutenberg.org/cache/epub/4723/pg4723.txt')\r\n",
        "berkeley_three_dialogues = get_guten('http://www.gutenberg.org/cache/epub/4724/pg4724.txt')\r\n",
        "\r\n",
        "## german idealism\r\n",
        "kant_practical_reason = get_text(drive_path + '/phil_txts/kant_critique_practical_reason.txt')\r\n",
        "kant_judgement = get_text(drive_path + '/phil_txts/kant_critique_judgement.txt')\r\n",
        "kant_pure_reason = get_text(drive_path + '/phil_txts/kant_pure_reason.txt')\r\n",
        "fichte_ethics = get_text(drive_path + '/phil_txts/fichte_system_of_ethics.txt')\r\n",
        "hegel_logic = get_text(drive_path + '/phil_txts/hegel_science_of_logic.txt')\r\n",
        "hegel_phenomenology = get_text(drive_path + '/phil_txts/hegel_phenomenology_of_spirit.txt')\r\n",
        "hegel_right = get_text(drive_path + '/phil_txts/hegel_elements_of_right.txt')\r\n",
        "\r\n",
        "## analytic\r\n",
        "russell_problems_of_phil = get_guten('http://www.gutenberg.org/cache/epub/5827/pg5827.txt')\r\n",
        "russell_analylsis_of_mind = get_guten('http://www.gutenberg.org/cache/epub/2529/pg2529.txt')\r\n",
        "moore_studies = get_guten('http://www.gutenberg.org/files/50141/50141-0.txt')\r\n",
        "wittgenstein_tractatus = get_text(drive_path + '/phil_txts/wittgenstein_tractatus.txt')\r\n",
        "wittgenstein_investigations = get_text(drive_path + '/phil_txts/wittgenstien_philosophical_investigations.txt')\r\n",
        "lewis_papers1 = get_text(drive_path + '/phil_txts/lewis_papers_1.txt')\r\n",
        "lewis_papers2 = get_text(drive_path + '/phil_txts/lewis_papers_2.txt')\r\n",
        "quine_quintessence = get_text(drive_path + '/phil_txts/quine_quintessence.txt')\r\n",
        "popper_science = get_text(drive_path + '/phil_txts/popper_logic_of_science.txt')\r\n",
        "kripke_troubles = get_text(drive_path + '/phil_txts/kripke_philosophical_troubles.txt')\r\n",
        "kripke_naming = get_text(drive_path + '/phil_txts/kripke_naming_necessity.txt')\r\n",
        "\r\n",
        "## phenomenology\r\n",
        "ponty_perception = get_text(drive_path + '/phil_txts/merleau-ponty_phenomenology_of_perception.txt')\r\n",
        "husserl_idea_of = get_text(drive_path + '/phil_txts/husserl_idea_of_phenomenology.txt')\r\n",
        "husserl_crisis = get_text(drive_path + '/phil_txts/husserl_crisis_of_euro_sciences.txt')\r\n",
        "husserl_cartesian = get_text(drive_path + '/phil_txts/husserl_cartesian_meditations.txt')\r\n",
        "heidegger_being_time = get_text(drive_path + '/phil_txts/heidegger_being_and_time.txt')\r\n",
        "heidegger_track = get_text(drive_path + '/phil_txts/heidegger_off_the_beaten_track.txt')\r\n",
        "\r\n",
        "## continental\r\n",
        "foucault_order = get_text(drive_path + '/phil_txts/foucault_order_of_things.txt')\r\n",
        "foucault_madness = get_text(drive_path + '/phil_txts/foucault_history_of_madness.txt')\r\n",
        "foucault_clinic = get_text(drive_path + '/phil_txts/foucault_birth_of_clinic.txt')\r\n",
        "derrida_writing = get_text(drive_path + '/phil_txts/derrida_writing_difference.txt')\r\n",
        "deleuze_oedipus = get_text(drive_path + '/phil_txts/deleuze_guattari_anti-oedipus.txt')\r\n",
        "deleuze_difference = get_text(drive_path + '/phil_txts/deleuze_difference_repetition.txt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms3YpA9V5qQR"
      },
      "source": [
        "Now we cut out front and end-matter. This needs to be done ad hoc, since there is no consistent marker for it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEZNb46c6Hbw"
      },
      "source": [
        "plato_complete = plato_complete.split('find that an enticing')[1][388:].split('Demeter, whose cult at')[0]\r\n",
        "aristotle_vol_1 = aristotle_vol1.split('1a20-1b9')[1].split('799a16')[0]\r\n",
        "aristotle_vol_2 = aristotle_vol2.split('830a5-830b4')[1].split('1462a5-1462a13')[0]\r\n",
        "spinoza_ethics = spinoza_ethics.split('ranslated from the Latin by R.')[1][71:].split('End of the Ethics')[0]\r\n",
        "spinoza_improve_understanding = spinoza_improve_understanding.split('Farewell.*')[1][20:].split('End of ')[0]\r\n",
        "leibniz_theodicy = leibniz_theodicy.split('appeared in 1710 as the')[1][202:].split('SUMMARY OF THE CON')[0][:-140]\r\n",
        "descartes_discourse_method = descartes_discourse_method.split('PREFATORY NOTE')[1][18:].split('End of the Pr')[0]\r\n",
        "descartes_meditations = descartes_meditations.split('LETTER')[1][1:].split('EXPLANATORY NOTES')[0][:-8]\r\n",
        "locke_understanding_1 = locke_understanding_1.split('2 Dorset Court, 24th of May, 1689')[1][50:].split('End of the Pro')[0][:-30]\r\n",
        "locke_understanding_2 = locke_understanding_2.split('1. Man fitted to form articulated Sounds.')[1][4:].split('End of the Pro')[0][:-25]\r\n",
        "malebranche_search_truth = malebranche_search_truth.split(\"n's Mind and the Use H\")[1][64:].split('Beati qui')[0]\r\n",
        "locke_treatise_gov = locke_treatise_gov.split('now lodged in Christ College, Cambridge.')[1][21:].split('FINIS.')[0]\r\n",
        "hume_treatise = hume_treatise.split('ADVERTISEMENT')[1][9:].split('End of Pro')[0][:-14]\r\n",
        "hume_natural_religion = hume_natural_religion.split('PAMPHILUS TO HERMIPPUS')[1][6:].split('End of the Pro')[0][:-22]\r\n",
        "berkeley_treatise = berkeley_treatise.split('are too apt to condemn an opinion before they rightly')[1][47:].split('End of the Pr')[0][:-22]\r\n",
        "berkeley_three_dialogues = berkeley_three_dialogues.split('THE FIRST DIALOGUE')[1][17:].split('End of the Pro')[0][:-22]\r\n",
        "kant_practical_reason = kant_practical_reason.split('erner Pluhar an')[1][329:].split('stone of the wi')[0][:-20]\r\n",
        "kant_judgement = kant_judgement.split('TO THE FIRST EDITION,* 1790')[1][1:].split('EXPLANATORY NOTES')[0][:-39]\r\n",
        "kant_pure_reason = kant_pure_reason.split('Bacon of Verulam')[1][33:].split('(Persius, Satires, iii, 78-9).')[0][:-1]\r\n",
        "fichte_ethics = fichte_ethics.split('(“Krause Nachschrift,” 1798/99)')[1][111:].split('Page 345')[0][:-2]\r\n",
        "hegel_logic = hegel_logic.split('complete transformati')[1][249:].split('It is a matter of speculation how Hegel would have rev')[0][:-80]\r\n",
        "hegel_phenomenology = hegel_phenomenology.split('PREFACE: ON SCIENTIFIC')[1][1:].split('1I Adaptation')[0][:-62]\r\n",
        "hegel_right = hegel_right.split('he immediate occasion f')[1][184:].split('I Hegel lectured on the topics in')[0][:-28]\r\n",
        "russell_problems_of_phil = russell_problems_of_phil.split('n the following pages')[1].split('BIBLIOGRAPHICAL NOTE')[0]\r\n",
        "russell_analylsis_of_mind = russell_analylsis_of_mind.split('H. D. Lewis')[2][21:].split('End of Pro')[0]\r\n",
        "moore_studies = moore_studies.split('Aristotelian Society,_ 1919-20.')[1][23:].split('E Wes')[0][:-10]\r\n",
        "wittgenstein_tractatus = wittgenstein_tractatus.split('TRACTATUS LOGICO-PHILOSOPHICUS')[1][70:].split('I NDEX')[0][:-8]\r\n",
        "wittgenstein_investigations = wittgenstein_investigations.split('catty')[1][787:].split(\"above', 351\")[0]\r\n",
        "lewis_papers1 = lewis_papers1.split('The fifteen papers')[1][61:].split('Acquai')[0][:-10]\r\n",
        "lewis_papers2 = lewis_papers2.split('Part Four Counterfactuals and Time')[1][17:].split('end p.342')[0]\r\n",
        "quine_quintessence = quine_quintessence.split('T R UT H B Y C O N V E N T I O N')[1].split('CREDITS')[0][:-7]\r\n",
        "popper_science = popper_science.split('F IRST E NGLISH E DITION, 1959')[1][2:].split('This is the end of the text of the original book.')[0]\r\n",
        "kripke_troubles = kripke_troubles.split('apters 2, 3, 7, 10, 11, and 13 are previously unpublish')[1][103:].split('ans, Gareth. 198')[0][:-25]\r\n",
        "kripke_naming = kripke_naming.split('xjvdsa')[1][10:].split('hese addenda represe')[0][:-35]\r\n",
        "ponty_perception = ponty_perception.split('P REFACE')[1].split('B IBLIOGRAPHY')[0][:-65]\r\n",
        "husserl_idea_of = husserl_idea_of.split('LECTUREl')[1][9:].split('Abstraction, ideating, 47, 50, 65')[0][:-10]\r\n",
        "husserl_crisis = husserl_crisis.split('§ 1.')[1].split('Appendix X:')[0]\r\n",
        "husserl_cartesian = husserl_cartesian.split('of philosophical reflection.')[1].split('n. 72.')[0][:-5]\r\n",
        "heidegger_being_time = heidegger_being_time.split(\"AUTHOR'S PREFACE TO THE\")[1][25:].split('Not \"the\" sole way.')[0][:-8]\r\n",
        "heidegger_track = heidegger_track.split('translated in several ')[1][15:].split('et-up [dar Gestellj as the uunost obli')[0][:-32]\r\n",
        "foucault_order = foucault_order.split('P REFACE')[1]\r\n",
        "foucault_madness = foucault_madness.split('ickering simulacra, an')[1][112:].split('Page 591')[0]\r\n",
        "foucault_clinic = foucault_clinic.split('iagnostic (Paris, 1962, p.')[1][15:].split('de Sade.')[0][:-33]\r\n",
        "derrida_writing = derrida_writing.split('(Flaubert, Preface d la d')[1][10:].split('Reb Derissa')[0]\r\n",
        "deleuze_oedipus = deleuze_oedipus.split('xjdsde')[1].split('jajielaks')[0]\r\n",
        "deleuze_difference = deleuze_difference.split('Introduction:')[1].split('Plateaus')[0][:-65]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k1vYwyP6M08"
      },
      "source": [
        "Having isolated the relevant portions of each document, we can now unify all the texts in each school."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzWPHDDB-agr"
      },
      "source": [
        "# a list of books for each school, then aggregated and entered into a dictionary\r\n",
        "plato_texts = [plato_complete]\r\n",
        "aristotle_texts = [aristotle_vol1, aristotle_vol2]\r\n",
        "rationalist_texts = [spinoza_ethics, spinoza_improve_understanding, leibniz_theodicy, descartes_discourse_method, descartes_meditations, malebranche_search_truth]\r\n",
        "empiricist_texts = [locke_treatise_gov, locke_understanding_1, locke_understanding_2, hume_treatise, hume_natural_religion, berkeley_three_dialogues, berkeley_treatise]\r\n",
        "german_idealist_texts = [kant_practical_reason, kant_judgement, kant_pure_reason, fichte_ethics, hegel_logic, hegel_phenomenology, hegel_right]\r\n",
        "analytic_texts = [russell_analylsis_of_mind, russell_problems_of_phil, moore_studies, wittgenstein_investigations, wittgenstein_tractatus, lewis_papers1, lewis_papers2, quine_quintessence, popper_science, kripke_naming, kripke_troubles]\r\n",
        "phenomenology_texts = [ponty_perception, husserl_cartesian, husserl_crisis, husserl_idea_of, heidegger_being_time, heidegger_track]\r\n",
        "continental_texts = [foucault_clinic, foucault_madness, foucault_order, derrida_writing, deleuze_difference, deleuze_oedipus]\r\n",
        "\r\n",
        "all_texts = plato_texts + aristotle_texts + empiricist_texts + rationalist_texts + analytic_texts + continental_texts + phenomenology_texts + german_idealist_texts\r\n",
        "    \r\n",
        "text_dict = {'plato': plato_texts, 'aristotle': aristotle_texts, 'empiricism': empiricist_texts, 'rationalism': rationalist_texts, \r\n",
        "            'german_idealism': german_idealist_texts, 'phenomenology': phenomenology_texts, 'analytic': analytic_texts, \r\n",
        "            'continental': continental_texts}\r\n",
        "    \r\n",
        "for school in text_dict.keys():\r\n",
        "    text_dict[school] = ' . '.join(text_dict[school])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDwClVWb-boW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}