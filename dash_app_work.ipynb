{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dash_app_work.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNT+5pFHiB1EnDiuEA5ZgFX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcalizadeh/phil_nlp/blob/master/dash_app_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXenaoRHXmAz"
      },
      "source": [
        "### Imports and Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2Al9oIXXvwS",
        "outputId": "4f3e02f2-e9ec-4d52-bc07-c992731246d4"
      },
      "source": [
        "# this cell mounts drive, sets the correct directory, then imports all functions\r\n",
        "# and relevant libraries via the functions.py file\r\n",
        "from google.colab import drive\r\n",
        "import sys\r\n",
        "\r\n",
        "# install relevent libraries not included with colab\r\n",
        "!pip install lime\r\n",
        "!pip install symspellpy\r\n",
        "!pip install jupyter-dash\r\n",
        "!pip install dash-bootstrap-components\r\n",
        "\r\n",
        "\r\n",
        "drive.mount('/gdrive',force_remount=True)\r\n",
        "\r\n",
        "drive_path = '/gdrive/MyDrive/Colab_Projects/Phil_NLP'\r\n",
        "\r\n",
        "sys.path.append(drive_path)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/86/91a13127d83d793ecb50eb75e716f76e6eda809b6803c5a4ff462339789e/lime-0.2.0.1.tar.gz (275kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 22.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 16.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 194kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 225kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 235kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 256kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.19.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->lime) (1.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.5)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-cp36-none-any.whl size=283846 sha256=3ed22479e7648de2cab7fb5923c86bf9cd1280256810168a153274c562675990\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/4f/a5/0bc765457bd41378bf3ce8d17d7495369d6e7ca3b712c60c89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n",
            "Collecting symspellpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/af/e71fcca6a42b6a63f518b0c1627e1f67822815cb0cf71e6af05acbd75c78/symspellpy-6.7.0-py3-none-any.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.19.4)\n",
            "Installing collected packages: symspellpy\n",
            "Successfully installed symspellpy-6.7.0\n",
            "Requirement already satisfied: jupyter-dash in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (2.23.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (1.1.2)\n",
            "Requirement already satisfied: dash in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (1.18.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (5.5.0)\n",
            "Requirement already satisfied: ansi2html in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (1.6.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (4.10.1)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (1.3.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->jupyter-dash) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->jupyter-dash) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->jupyter-dash) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->jupyter-dash) (2020.12.5)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask->jupyter-dash) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->jupyter-dash) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->jupyter-dash) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->jupyter-dash) (1.1.0)\n",
            "Requirement already satisfied: flask-compress in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (1.8.0)\n",
            "Requirement already satisfied: dash-table==4.11.1 in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (4.11.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (0.16.0)\n",
            "Requirement already satisfied: dash-core-components==1.14.1 in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (1.14.1)\n",
            "Requirement already satisfied: dash-html-components==1.1.1 in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (1.1.1)\n",
            "Requirement already satisfied: dash-renderer==1.8.3 in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (1.8.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (4.4.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (4.3.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (51.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (2.6.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter-dash) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter-dash) (5.1.1)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from retrying->jupyter-dash) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->jupyter-dash) (1.1.1)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.6/dist-packages (from flask-compress->dash->jupyter-dash) (1.0.9)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyter-dash) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->jupyter-dash) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (4.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (20.0.0)\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWcK2Wb4ZTfY",
        "outputId": "e678cb99-7197-4d65-f3dc-4f439187c51d"
      },
      "source": [
        "from functions import *\r\n",
        "%load_ext autoreload\r\n",
        "%autoreload 2\r\n",
        "\r\n",
        "np.random.seed(17)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning:\n",
            "\n",
            "The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning:\n",
            "\n",
            "The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv6-A8_kGUUb"
      },
      "source": [
        "class Padder(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self, maxlen=500):\r\n",
        "        self.maxlen = maxlen\r\n",
        "        self.max_index = None\r\n",
        "        \r\n",
        "    def fit(self, X, y=None):\r\n",
        "        self.max_index = pad_sequences(X, maxlen=self.maxlen).max()\r\n",
        "        return self\r\n",
        "    \r\n",
        "    def transform(self, X, y=None):\r\n",
        "        X = pad_sequences(X, maxlen=self.maxlen)\r\n",
        "        # X[X > self.max_index] = 0\r\n",
        "        return X\r\n",
        "\r\n",
        "padder = Padder(450)"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKAdBCV-N4wm"
      },
      "source": [
        "class TextsToSequences(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self,  tokenizer):\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        \r\n",
        "    def fit(self, texts, y=None):\r\n",
        "        return self\r\n",
        "    \r\n",
        "    def transform(self, texts, y=None):\r\n",
        "        return np.array(self.tokenizer.texts_to_sequences(texts))\r\n",
        "        \r\n",
        "sequencer = TextsToSequences(tokenizer)"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "-gtorzn5X0IF",
        "outputId": "c6efd1b7-8a11-4d4d-8aaf-9306493a0cff"
      },
      "source": [
        "import plotly.express as px\r\n",
        "from jupyter_dash import JupyterDash\r\n",
        "import dash_core_components as dcc\r\n",
        "import dash_html_components as html\r\n",
        "import dash_bootstrap_components as dbc\r\n",
        "from dash.dependencies import Input, Output, State\r\n",
        "\r\n",
        "# Load Data\r\n",
        "df = pd.read_csv('/gdrive/MyDrive/Colab_Projects/Phil_NLP/phil_nlp.csv')\r\n",
        "\r\n",
        "model_path = '/gdrive/MyDrive/Colab_Projects/Phil_NLP/checkpoints/NN_weights_epoch:07_0.7678.hdf5'\r\n",
        "model = load_model(model_path)\r\n",
        "\r\n",
        "with open('/gdrive/MyDrive/Colab_Projects/Phil_NLP/baseline_tokenizer.pkl', 'rb') as f:\r\n",
        "    tokenizer = pickle.load(f)\r\n",
        "\r\n",
        "# set up classification explanation pipeline\r\n",
        "padder = Padder(450)\r\n",
        "sequencer = TextsToSequences(tokenizer)\r\n",
        "pipeline = make_pipeline(sequencer, padder, model)\r\n",
        "\r\n",
        "# set up labels\r\n",
        "school_label_dict = {'analytic': 0,\r\n",
        " 'aristotle': 1,\r\n",
        " 'capitalism': 2,\r\n",
        " 'communism': 3,\r\n",
        " 'continental': 4,\r\n",
        " 'empiricism': 5,\r\n",
        " 'german_idealism': 6,\r\n",
        " 'phenomenology': 7,\r\n",
        " 'plato': 8,\r\n",
        " 'rationalism': 9}\r\n",
        "flipped_dict = {value:key for key, value in school_label_dict.items()}\r\n",
        "\r\n",
        "# search bar object\r\n",
        "search_bar = html.Div(id=\"search-bar-container\", children=\r\n",
        "    [\r\n",
        "        dbc.Input(id=\"search-bar\", placeholder=\"enter text to classify\", type=\"text\"),\r\n",
        "        dbc.Button(\"SUBMIT\", id=\"search-bar-submit-button\", color=\"primary\", className=\"mr-1\", n_clicks=0)\r\n",
        "    ])\r\n",
        "\r\n",
        "\r\n",
        "# the app itself\r\n",
        "app = JupyterDash(__name__)\r\n",
        "app.layout = html.Div([\r\n",
        "    html.H1(\"Text Classification\"),\r\n",
        "    search_bar,\r\n",
        "    html.Div(id=\"search-bar-output\", children=[]),\r\n",
        "\r\n",
        "])\r\n",
        "\r\n",
        "\r\n",
        "# callback for search bar\r\n",
        "@app.callback(Output(component_id=\"search-bar-output\", component_property=\"children\"),\r\n",
        "              [Input(component_id=\"search-bar-submit-button\", component_property=\"n_clicks\")],\r\n",
        "              [State(component_id=\"search-bar\", component_property=\"value\")])\r\n",
        "def generate_explainer_html(n_clicks, text):\r\n",
        "    empty_obj = html.Iframe(\r\n",
        "        srcDoc='''<div>Enter input text to see LIME explanations.</div>''',\r\n",
        "        width='100%',\r\n",
        "        height='100px',\r\n",
        "        style={'border': '2px #d3d3d3 solid'},\r\n",
        "        hidden=True,\r\n",
        "    )\r\n",
        "    if n_clicks < 1 or text == '':\r\n",
        "      return empty_obj\r\n",
        "    else:\r\n",
        "      explainer = lime_text.LimeTextExplainer(class_names=list(school_label_dict.keys()))\r\n",
        "      exp = explainer.explain_instance(text, pipeline.predict, num_features=10, labels=[0,1,2,3,4,5,6,7,8,9])\r\n",
        "      obj = html.Iframe(\r\n",
        "          srcDoc=exp.as_html(),\r\n",
        "          width='100%',\r\n",
        "          height='800px',\r\n",
        "          style={'border': '2px #d3d3d3 solid'},\r\n",
        "      )\r\n",
        "      return obj\r\n",
        "\r\n",
        "# Run app and display result inline in the notebook\r\n",
        "app.run_server(mode='inline')"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = url + path;\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05q4fO6kay8C"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BIo730TX-qD"
      },
      "source": [
        "model_path = '/gdrive/MyDrive/Colab_Projects/Phil_NLP/checkpoints/NN_weights_epoch:07_0.7678.hdf5'\r\n",
        "model = load_model(model_path)\r\n",
        "\r\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09l49K48bJsM"
      },
      "source": [
        ""
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHjCt6bza31C",
        "outputId": "33577141-ef9f-43aa-81bb-730fcc832404"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10844288  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                35800     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                260       \n",
            "=================================================================\n",
            "Total params: 10,881,623\n",
            "Trainable params: 10,881,623\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJfu3Ae0a_q-"
      },
      "source": [
        "with open('/gdrive/MyDrive/Colab_Projects/Phil_NLP/baseline_tokenizer.pkl', 'rb') as f:\r\n",
        "    tokenizer = pickle.load(f)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlSrRWcEgBXq"
      },
      "source": [
        "to_classify = 'Knowledge of the Idea of the absolute ethical order depends entirely on the establishment of perfect adequacy between intuition and concept, because the Idea itself is nothing other than the identity of the two. But if this identity is to be actually known, it must be thought as a made adequacy.'"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdLwCxJ60ht8"
      },
      "source": [
        "pipeline = make_pipeline(sequencer, padder, model)"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cm36OB4zP89",
        "outputId": "6f0ef697-d99d-4e21-ca57-d79f03b3702e"
      },
      "source": [
        "pd.Series(to_classify)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Knowledge of the Idea of the absolute ethical ...\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDP4U8aDgIH_"
      },
      "source": [
        "tokenized = tokenizer.texts_to_sequences(pd.Series(to_classify))"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjwcZwrhgrVa"
      },
      "source": [
        "padded = sequence.pad_sequences(tokenized, maxlen=450)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0g2hXNQV5yR8",
        "outputId": "72e35474-f58c-4b6b-9f9d-9b5324fa18f6"
      },
      "source": [
        "flipped_dict[pipeline.predict(pd.Series(to_classify)).argmax()]"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'german_idealism'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyZClxsmgc00",
        "outputId": "7cc5ffba-41ae-430b-ba29-b1b230f6b125"
      },
      "source": [
        "prediction_num = model.predict(padded, verbose=1)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpR4AOgpvrXY",
        "outputId": "6249c94e-5b2f-474b-fcfd-819f8b2565b0"
      },
      "source": [
        "prediction_num.argmax()"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oHuX7TCgzYin",
        "outputId": "4bed7928-9ced-4728-9caf-d57e4e3c9bf2"
      },
      "source": [
        "flipped_dict[prediction_num.argmax()]"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'german_idealism'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv9-APXr29aC",
        "outputId": "3dd37204-65f1-44c1-c972-de9b8f7fb7c1"
      },
      "source": [
        "list(school_label_dict.keys())"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['analytic',\n",
              " 'aristotle',\n",
              " 'capitalism',\n",
              " 'communism',\n",
              " 'continental',\n",
              " 'empiricism',\n",
              " 'german_idealism',\n",
              " 'phenomenology',\n",
              " 'plato',\n",
              " 'rationalism']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuF8tsPb7CjO"
      },
      "source": [
        "to_classify = \"\"\"Hi Michelle and Kourosh-\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "Happy New Year to you both!\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "Was wondering if we could schedule a short touch base in the next few weeks? No concerns—rather—just want to get some feedback on Cole’s progress.\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "Could you suggest a few times that could work for you both?\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "thanks\"\"\""
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJk199u806kH"
      },
      "source": [
        "explainer = lime_text.LimeTextExplainer(class_names=list(school_label_dict.keys()))\r\n",
        "exp = explainer.explain_instance(to_classify, pipeline.predict, num_features=10, labels=[0,1,2,3,4,5,6,7,8,9])\r\n",
        "\r\n",
        "exp.show_in_notebook(text=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fN7cFP2hCNz"
      },
      "source": [
        "for i in prediction_num.argmax(axis=1):\r\n",
        "  print(flipped_dict[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pL78gvQgkpw"
      },
      "source": [
        "school_label_dict = {'analytic': 0,\r\n",
        " 'aristotle': 1,\r\n",
        " 'capitalism': 2,\r\n",
        " 'communism': 3,\r\n",
        " 'continental': 4,\r\n",
        " 'empiricism': 5,\r\n",
        " 'german_idealism': 6,\r\n",
        " 'phenomenology': 7,\r\n",
        " 'plato': 8,\r\n",
        " 'rationalism': 9}\r\n",
        "flipped_dict = {value:key for key, value in school_label_dict.items()}"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MaWbI7BhBdc"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.pipeline import TransformerMixin\r\n",
        "from sklearn.base import BaseEstimator\r\n",
        "\r\n",
        "class TextsToSequences(BaseEstimator, TransformerMixin):\r\n",
        "    \"\"\" Sklearn transformer to convert texts to indices list \r\n",
        "    (e.g. [[\"the cute cat\"], [\"the dog\"]] -> [[1, 2, 3], [1, 4]])\"\"\"\r\n",
        "    def __init__(self,  tokenizer, **kwargs):\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        \r\n",
        "    def fit(self, texts, y=None):\r\n",
        "        return self\r\n",
        "    \r\n",
        "    def transform(self, texts, y=None):\r\n",
        "        return np.array(self.tokenizer.texts_to_sequences(texts))\r\n",
        "        \r\n",
        "sequencer = TextsToSequences(tokenizer, num_words=450)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiUHD02_4BAj"
      },
      "source": [
        "class Padder(BaseEstimator, TransformerMixin):\r\n",
        "    \"\"\" Pad and crop uneven lists to the same length. \r\n",
        "    Only the end of lists longer than the maxlen attribute are\r\n",
        "    kept, and lists shorter than maxlen are left-padded with zeros\r\n",
        "    \r\n",
        "    Attributes\r\n",
        "    ----------\r\n",
        "    maxlen: int\r\n",
        "        sizes of sequences after padding\r\n",
        "    max_index: int\r\n",
        "        maximum index known by the Padder, if a higher index is met during \r\n",
        "        transform it is transformed to a 0\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, maxlen=500):\r\n",
        "        self.maxlen = maxlen\r\n",
        "        self.max_index = None\r\n",
        "        \r\n",
        "    def fit(self, X, y=None):\r\n",
        "        self.max_index = pad_sequences(X, maxlen=self.maxlen).max()\r\n",
        "        return self\r\n",
        "    \r\n",
        "    def transform(self, X, y=None):\r\n",
        "        X = pad_sequences(X, maxlen=self.maxlen)\r\n",
        "        # X[X > self.max_index] = 0\r\n",
        "        return X\r\n",
        "\r\n",
        "padder = Padder(450)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0amhwL1JbU4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}