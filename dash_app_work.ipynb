{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dash_app_work.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOkvf/vlsjURTwsXebtm3yz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcalizadeh/phil_nlp/blob/master/dash_app_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXenaoRHXmAz"
      },
      "source": [
        "### Imports and Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2Al9oIXXvwS",
        "outputId": "89bdd72f-d093-41be-8621-d3e89acd73dc"
      },
      "source": [
        "# this cell mounts drive, sets the correct directory, then imports all functions\r\n",
        "# and relevant libraries via the functions.py file\r\n",
        "from google.colab import drive\r\n",
        "import sys\r\n",
        "\r\n",
        "# install relevent libraries not included with colab\r\n",
        "!pip install lime\r\n",
        "!pip install symspellpy\r\n",
        "!pip install jupyter-dash\r\n",
        "!pip install dash-bootstrap-components\r\n",
        "\r\n",
        "\r\n",
        "drive.mount('/gdrive',force_remount=True)\r\n",
        "\r\n",
        "drive_path = '/gdrive/MyDrive/Colab_Projects/Phil_NLP'\r\n",
        "\r\n",
        "sys.path.append(drive_path)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.6/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->lime) (1.0.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.5)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Requirement already satisfied: symspellpy in /usr/local/lib/python3.6/dist-packages (6.7.0)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.19.5)\n",
            "Requirement already satisfied: jupyter-dash in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (5.5.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (1.1.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (4.10.1)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (1.3.3)\n",
            "Requirement already satisfied: ansi2html in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (1.6.0)\n",
            "Requirement already satisfied: dash in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (1.18.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from jupyter-dash) (2.23.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (51.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-dash) (4.8.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask->jupyter-dash) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->jupyter-dash) (2.11.2)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->jupyter-dash) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->jupyter-dash) (1.1.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter-dash) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter-dash) (5.1.1)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from retrying->jupyter-dash) (1.15.0)\n",
            "Requirement already satisfied: dash-html-components==1.1.1 in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (1.1.1)\n",
            "Requirement already satisfied: dash-table==4.11.1 in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (4.11.1)\n",
            "Requirement already satisfied: flask-compress in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (1.8.0)\n",
            "Requirement already satisfied: dash-renderer==1.8.3 in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (1.8.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (4.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (0.16.0)\n",
            "Requirement already satisfied: dash-core-components==1.14.1 in /usr/local/lib/python3.6/dist-packages (from dash->jupyter-dash) (1.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->jupyter-dash) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->jupyter-dash) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->jupyter-dash) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->jupyter-dash) (2.10)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyter-dash) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->jupyter-dash) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->jupyter-dash) (1.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (20.0.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (4.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.1)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.6/dist-packages (from flask-compress->dash->jupyter-dash) (1.0.9)\n",
            "Requirement already satisfied: dash-bootstrap-components in /usr/local/lib/python3.6/dist-packages (0.11.1)\n",
            "Requirement already satisfied: dash>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from dash-bootstrap-components) (1.18.1)\n",
            "Requirement already satisfied: dash-html-components==1.1.1 in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (1.1.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (4.4.1)\n",
            "Requirement already satisfied: dash-core-components==1.14.1 in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (1.14.1)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (1.1.2)\n",
            "Requirement already satisfied: dash-renderer==1.8.3 in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (1.8.3)\n",
            "Requirement already satisfied: flask-compress in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (1.8.0)\n",
            "Requirement already satisfied: dash-table==4.11.1 in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (4.11.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from dash>=1.9.0->dash-bootstrap-components) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly->dash>=1.9.0->dash-bootstrap-components) (1.15.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->dash>=1.9.0->dash-bootstrap-components) (1.3.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.4->dash>=1.9.0->dash-bootstrap-components) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.4->dash>=1.9.0->dash-bootstrap-components) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.4->dash>=1.9.0->dash-bootstrap-components) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.4->dash>=1.9.0->dash-bootstrap-components) (7.1.2)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.6/dist-packages (from flask-compress->dash>=1.9.0->dash-bootstrap-components) (1.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.4->dash>=1.9.0->dash-bootstrap-components) (1.1.1)\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWcK2Wb4ZTfY",
        "outputId": "de5dcf6f-ff88-43c3-941e-aee7077e3b35"
      },
      "source": [
        "%load_ext autoreload\r\n",
        "%autoreload 2\r\n",
        "from functions import *\r\n",
        "\r\n",
        "np.random.seed(17)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv08eNYlWOzj"
      },
      "source": [
        "### Text Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmHP47PsWSoI"
      },
      "source": [
        "In order to set up the text classifier via Lime, we need to build a pipeline that can tokenize and pad text for use with our neural network models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv6-A8_kGUUb"
      },
      "source": [
        "class Padder(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self, maxlen=500):\r\n",
        "        self.maxlen = maxlen\r\n",
        "        self.max_index = None\r\n",
        "        \r\n",
        "    def fit(self, X, y=None):\r\n",
        "        self.max_index = pad_sequences(X, maxlen=self.maxlen).max()\r\n",
        "        return self\r\n",
        "    \r\n",
        "    def transform(self, X, y=None):\r\n",
        "        X = pad_sequences(X, maxlen=self.maxlen)\r\n",
        "        # X[X > self.max_index] = 0\r\n",
        "        return X"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKAdBCV-N4wm"
      },
      "source": [
        "class TextsToSequences(BaseEstimator, TransformerMixin):\r\n",
        "    def __init__(self,  tokenizer):\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        \r\n",
        "    def fit(self, texts, y=None):\r\n",
        "        return self\r\n",
        "    \r\n",
        "    def transform(self, texts, y=None):\r\n",
        "        return np.array(self.tokenizer.texts_to_sequences(texts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6fdSOJ2WiCs"
      },
      "source": [
        "The following cell runs the app in the notebook. At this point it is unformatted, but the callbacks work and it will display a text analysis breakdown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gtorzn5X0IF"
      },
      "source": [
        "import plotly.express as px\r\n",
        "from jupyter_dash import JupyterDash\r\n",
        "import dash_core_components as dcc\r\n",
        "import dash_html_components as html\r\n",
        "import dash_bootstrap_components as dbc\r\n",
        "from dash.dependencies import Input, Output, State\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "\r\n",
        "# Load Data\r\n",
        "df = pd.read_csv('/gdrive/MyDrive/Colab_Projects/Phil_NLP/phil_nlp.csv')\r\n",
        "\r\n",
        "model_path = '/gdrive/MyDrive/Colab_Projects/Phil_NLP/checkpoints/NN_weights_epoch:07_0.7678.hdf5'\r\n",
        "model = load_model(model_path)\r\n",
        "\r\n",
        "with open('/gdrive/MyDrive/Colab_Projects/Phil_NLP/baseline_tokenizer.pkl', 'rb') as f:\r\n",
        "    tokenizer = pickle.load(f)\r\n",
        "\r\n",
        "# set up classification explanation pipeline\r\n",
        "padder = Padder(450)\r\n",
        "sequencer = TextsToSequences(tokenizer)\r\n",
        "pipeline = make_pipeline(sequencer, padder, model)\r\n",
        "\r\n",
        "# set up labels\r\n",
        "school_label_dict = {'analytic': 0,\r\n",
        " 'aristotle': 1,\r\n",
        " 'capitalism': 2,\r\n",
        " 'communism': 3,\r\n",
        " 'continental': 4,\r\n",
        " 'empiricism': 5,\r\n",
        " 'german_idealism': 6,\r\n",
        " 'phenomenology': 7,\r\n",
        " 'plato': 8,\r\n",
        " 'rationalism': 9}\r\n",
        "flipped_dict = {value:key for key, value in school_label_dict.items()}\r\n",
        "\r\n",
        "# search bar object\r\n",
        "search_bar = html.Div(id=\"search-bar-container\", children=\r\n",
        "    [\r\n",
        "        dbc.Input(id=\"search-bar\", placeholder=\"enter text to classify\", type=\"text\"),\r\n",
        "        dbc.Button(\"SUBMIT\", id=\"search-bar-submit-button\", color=\"primary\", className=\"mr-1\", n_clicks=0)\r\n",
        "    ])\r\n",
        "\r\n",
        "\r\n",
        "# the app itself\r\n",
        "app = JupyterDash(__name__)\r\n",
        "app.layout = html.Div([\r\n",
        "    html.H1(\"Text Classification\"),\r\n",
        "    search_bar,\r\n",
        "    html.Div(id=\"search-bar-output\", children=[])  \r\n",
        "])\r\n",
        "\r\n",
        "\r\n",
        "# callback for search bar\r\n",
        "@app.callback(Output(component_id=\"search-bar-output\", component_property=\"children\"),\r\n",
        "              [Input(component_id=\"search-bar-submit-button\", component_property=\"n_clicks\")],\r\n",
        "              [State(component_id=\"search-bar\", component_property=\"value\")])\r\n",
        "def generate_explainer_html(n_clicks, text):\r\n",
        "    empty_obj = html.Iframe(\r\n",
        "        srcDoc='''<div>Enter input text to see LIME explanations.</div>''',\r\n",
        "        width='100%',\r\n",
        "        height='100px',\r\n",
        "        style={'border': '2px #d3d3d3 solid'},\r\n",
        "        hidden=True,\r\n",
        "    )\r\n",
        "    if n_clicks < 1 or text == '':\r\n",
        "      return empty_obj\r\n",
        "    else:\r\n",
        "      explainer = lime_text.LimeTextExplainer(class_names=list(school_label_dict.keys()))\r\n",
        "      exp = explainer.explain_instance(text, pipeline.predict, num_features=10, labels=[0,1,2,3,4,5,6,7,8,9])\r\n",
        "      obj = html.Iframe(\r\n",
        "          srcDoc=exp.as_html(),\r\n",
        "          width='100%',\r\n",
        "          height='800px',\r\n",
        "          style={'border': '2px #d3d3d3 solid'},\r\n",
        "      )\r\n",
        "      return obj\r\n",
        "\r\n",
        "\r\n",
        "# Run app and display result inline in the notebook\r\n",
        "app.run_server(mode='inline')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ritqCmr3NSo4"
      },
      "source": [
        "### W2V Explorer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkbtexxvNSO0"
      },
      "source": [
        "This app is designed to enable exploration of the texts via w2v models. Users can submit text to see how different philosophers use key terms. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "CIe4sQN6NRs0",
        "outputId": "d25b3f29-b1bf-415d-c13e-d7d30c9131e3"
      },
      "source": [
        "import plotly.express as px\r\n",
        "from jupyter_dash import JupyterDash\r\n",
        "import dash_core_components as dcc\r\n",
        "import dash_html_components as html\r\n",
        "import dash_bootstrap_components as dbc\r\n",
        "from dash.dependencies import Input, Output, State\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "\r\n",
        "custom_vectors = KeyedVectors.load('/gdrive/MyDrive/Colab_Projects/Phil_NLP/w2v_models/test_w2v.wordvectors')\r\n",
        "\r\n",
        "# search bar object\r\n",
        "search_bar = html.Div(id=\"search-bar-container\", children=\r\n",
        "    [\r\n",
        "        dbc.Input(id=\"search-bar\", placeholder=\"enter text to classify\", type=\"text\"),\r\n",
        "        dbc.Button(\"SUBMIT\", id=\"search-bar-submit-button\", color=\"primary\", className=\"mr-1\", n_clicks=0)\r\n",
        "    ])\r\n",
        "\r\n",
        "\r\n",
        "# the app itself\r\n",
        "app = JupyterDash(__name__)\r\n",
        "app.layout = html.Div([\r\n",
        "    html.H1(\"Word Similarity Search\"),\r\n",
        "    search_bar,\r\n",
        "    html.Div(id=\"search-bar-output\", children=[])  \r\n",
        "])\r\n",
        "\r\n",
        "\r\n",
        "# callback for search bar\r\n",
        "@app.callback(Output(component_id=\"search-bar-output\", component_property=\"children\"),\r\n",
        "              [Input(component_id=\"search-bar-submit-button\", component_property=\"n_clicks\")],\r\n",
        "              [State(component_id=\"search-bar\", component_property=\"value\")])\r\n",
        "def generate_explainer_html(n_clicks, text):\r\n",
        "    empty_obj = html.Iframe(\r\n",
        "        srcDoc='''<div>Enter input text to see LIME explanations.</div>''',\r\n",
        "        width='100%',\r\n",
        "        height='100px',\r\n",
        "        style={'border': '2px #d3d3d3 solid'},\r\n",
        "        hidden=True,\r\n",
        "    )\r\n",
        "    if n_clicks < 1 or text == '':\r\n",
        "      return empty_obj\r\n",
        "    else:\r\n",
        "      try:\r\n",
        "        similar_words = custom_vectors.most_similar(text)\r\n",
        "        formatted = [f'{x[0].title()}, {round(x[1], 3)}\\n\\n' for x in similar_words]\r\n",
        "        return formatted\r\n",
        "      except:\r\n",
        "        return 'Sorry, that word or phrase is not in the vocabulary'\r\n",
        "\r\n",
        "\r\n",
        "# Run app and display result inline in the notebook\r\n",
        "app.run_server(mode='external')\r\n",
        "\r\n",
        "# app"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dash app running on:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = url + path;\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8050, \"/\", \"http://127.0.0.1:8050/\", window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05q4fO6kay8C"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BIo730TX-qD"
      },
      "source": [
        "model_path = '/gdrive/MyDrive/Colab_Projects/Phil_NLP/checkpoints/NN_weights_epoch:07_0.7678.hdf5'\r\n",
        "model = load_model(model_path)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09l49K48bJsM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdivJ0n7PhfZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHjCt6bza31C",
        "outputId": "33577141-ef9f-43aa-81bb-730fcc832404"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         10844288  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                35800     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                260       \n",
            "=================================================================\n",
            "Total params: 10,881,623\n",
            "Trainable params: 10,881,623\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJfu3Ae0a_q-"
      },
      "source": [
        "with open('/gdrive/MyDrive/Colab_Projects/Phil_NLP/baseline_tokenizer.pkl', 'rb') as f:\r\n",
        "    tokenizer = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlSrRWcEgBXq"
      },
      "source": [
        "to_classify = 'Knowledge of the Idea of the absolute ethical order depends entirely on the establishment of perfect adequacy between intuition and concept, because the Idea itself is nothing other than the identity of the two. But if this identity is to be actually known, it must be thought as a made adequacy.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdLwCxJ60ht8"
      },
      "source": [
        "pipeline = make_pipeline(sequencer, padder, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cm36OB4zP89",
        "outputId": "6f0ef697-d99d-4e21-ca57-d79f03b3702e"
      },
      "source": [
        "pd.Series(to_classify)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Knowledge of the Idea of the absolute ethical ...\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDP4U8aDgIH_"
      },
      "source": [
        "tokenized = tokenizer.texts_to_sequences(pd.Series(to_classify))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjwcZwrhgrVa"
      },
      "source": [
        "padded = sequence.pad_sequences(tokenized, maxlen=450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g2hXNQV5yR8"
      },
      "source": [
        "flipped_dict[pipeline.predict(pd.Series(to_classify)).argmax()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyZClxsmgc00",
        "outputId": "7cc5ffba-41ae-430b-ba29-b1b230f6b125"
      },
      "source": [
        "prediction_num = model.predict(padded, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpR4AOgpvrXY",
        "outputId": "6249c94e-5b2f-474b-fcfd-819f8b2565b0"
      },
      "source": [
        "prediction_num.argmax()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHuX7TCgzYin"
      },
      "source": [
        "flipped_dict[prediction_num.argmax()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv9-APXr29aC",
        "outputId": "3dd37204-65f1-44c1-c972-de9b8f7fb7c1"
      },
      "source": [
        "list(school_label_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['analytic',\n",
              " 'aristotle',\n",
              " 'capitalism',\n",
              " 'communism',\n",
              " 'continental',\n",
              " 'empiricism',\n",
              " 'german_idealism',\n",
              " 'phenomenology',\n",
              " 'plato',\n",
              " 'rationalism']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuF8tsPb7CjO"
      },
      "source": [
        "to_classify = \"\"\"Hi Michelle and Kourosh-\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "Happy New Year to you both!\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "Was wondering if we could schedule a short touch base in the next few weeks? No concerns—rather—just want to get some feedback on Cole’s progress.\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "Could you suggest a few times that could work for you both?\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "thanks\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJk199u806kH"
      },
      "source": [
        "explainer = lime_text.LimeTextExplainer(class_names=list(school_label_dict.keys()))\r\n",
        "exp = explainer.explain_instance(to_classify, pipeline.predict, num_features=10, labels=[0,1,2,3,4,5,6,7,8,9])\r\n",
        "\r\n",
        "exp.show_in_notebook(text=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fN7cFP2hCNz"
      },
      "source": [
        "for i in prediction_num.argmax(axis=1):\r\n",
        "  print(flipped_dict[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pL78gvQgkpw"
      },
      "source": [
        "school_label_dict = {'analytic': 0,\r\n",
        " 'aristotle': 1,\r\n",
        " 'capitalism': 2,\r\n",
        " 'communism': 3,\r\n",
        " 'continental': 4,\r\n",
        " 'empiricism': 5,\r\n",
        " 'german_idealism': 6,\r\n",
        " 'phenomenology': 7,\r\n",
        " 'plato': 8,\r\n",
        " 'rationalism': 9}\r\n",
        "flipped_dict = {value:key for key, value in school_label_dict.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MaWbI7BhBdc"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.pipeline import TransformerMixin\r\n",
        "from sklearn.base import BaseEstimator\r\n",
        "\r\n",
        "class TextsToSequences(BaseEstimator, TransformerMixin):\r\n",
        "    \"\"\" Sklearn transformer to convert texts to indices list \r\n",
        "    (e.g. [[\"the cute cat\"], [\"the dog\"]] -> [[1, 2, 3], [1, 4]])\"\"\"\r\n",
        "    def __init__(self,  tokenizer, **kwargs):\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        \r\n",
        "    def fit(self, texts, y=None):\r\n",
        "        return self\r\n",
        "    \r\n",
        "    def transform(self, texts, y=None):\r\n",
        "        return np.array(self.tokenizer.texts_to_sequences(texts))\r\n",
        "        \r\n",
        "sequencer = TextsToSequences(tokenizer, num_words=450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiUHD02_4BAj"
      },
      "source": [
        "class Padder(BaseEstimator, TransformerMixin):\r\n",
        "    \"\"\" Pad and crop uneven lists to the same length. \r\n",
        "    Only the end of lists longer than the maxlen attribute are\r\n",
        "    kept, and lists shorter than maxlen are left-padded with zeros\r\n",
        "    \r\n",
        "    Attributes\r\n",
        "    ----------\r\n",
        "    maxlen: int\r\n",
        "        sizes of sequences after padding\r\n",
        "    max_index: int\r\n",
        "        maximum index known by the Padder, if a higher index is met during \r\n",
        "        transform it is transformed to a 0\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, maxlen=500):\r\n",
        "        self.maxlen = maxlen\r\n",
        "        self.max_index = None\r\n",
        "        \r\n",
        "    def fit(self, X, y=None):\r\n",
        "        self.max_index = pad_sequences(X, maxlen=self.maxlen).max()\r\n",
        "        return self\r\n",
        "    \r\n",
        "    def transform(self, X, y=None):\r\n",
        "        X = pad_sequences(X, maxlen=self.maxlen)\r\n",
        "        # X[X > self.max_index] = 0\r\n",
        "        return X\r\n",
        "\r\n",
        "padder = Padder(450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0amhwL1JbU4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}